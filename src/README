
# Introduction

#### Features

- spatialized audio
- metadata
- near field what's it?
- high dynamic range
- adaptive limiter
- adjustable noise-gate


#### Spatialized Audio

The Core Audio Engine defines a virtual 2D audio space.  Within the space are audio-sources and a listener, and each has a position within the virtual audio space.  The audio from each source is fed into an HRTF algorithm where it is manipulates to sound to the listener as if it comes from the source's relative direction and distance.  The web application can set or change the positions of sources and the listener, as well as the direction the listener is facing.

Optionally, changes to source positions can be synchronized across the network to other instances of the application.

#### Metadata

This library supports tight coupling and a high update-rate for a source's positional data.  If metadata is enabled, the audio stream from a local source will be modified to include the position of the source.  A TransportManager will send the modified stream across the network.  Other instances of the application will be able to extract the position of the source along with audio-data.  This allows for a very high rate for position updates and avoids any distracting desynchronization between how a source sounds and where its icon or character appears to be.

#### Near Field

We do something that sounds right if a source is very close to the listener

#### High Dynamic Range

All audio within this library is handled as 32-bit floats, which allows for an unlimited dynamic range.  This is important in applications where several or many sources may be producing sound at the same time.  More conventional handling of this mixed audio is likely to result in clipping and other artifacts.


WebRTC internally uses a 16-bit audio pipeline, and any stage that goes over, gets clipped. This sounds bad.
Web Audio uses floats and a pipeline of audio nodes can avoid this. But this still defers the problem. When you connect to a destination (audio device) it clips the floats to int16_t and sounds bad.
Our HDR solution uses Web Audio to process as floats, and has a tool at the end (a specialized lookahead peak-limiter) that does the final compression to 16-bit in a very high-quality way. It can handle huge overloads with almost no audible distortion.

#### Adaptive Limiter

When it's time to deliver audio from this library to the application, the higher dynamic-range data must be brought within the expected range.  This is the job of the Limiter.  It works by looking ahead several frames and very quickly adjusting the overall volume of the output stream.  This look-ahead allows the limiter to cap the loudness of the output without causing clicks or distortion.

#### Adjustable Noise Gate

The Adjustable Noise Gate can be placed between a microphone's output stream and the TransportManager's sender.  It works by squashing any audio that fails to cross an adjustable loudness threshold.  Any quiet background sound the mic may be picking up will be sent as total silence.  When a user speaks into their mic, the audio level will jump past the threshold and their voice will be transmitted.

# Installation

use npm somehow

# Getting Started

1. Include Agora's Client Javascript SDK
    ```html
    <script src="AgoraRTC_N-4.12.2.js"></script>
    ```

    More information can be found in Agora's quick-start documentation.
 
2. In the webpage, provide a "Join" button
   ```html
   <button id="join" type="submit" ">Join</button>
   ```

   Some browsers won't allow a web-page to start playing audio unless a user gesture triggers it. Chrome is one example. 

3. In the javascript portion of the web app, include the HiFiAudio library and a TransportManager.

    ```typescript
    import * as HiFiAudio from './hifi-audio.js'
    import { TransportManagerAgora } from "./hifi-transport-agora.js";
    ```

4. Set up callbacks

    To know when other users have joined or departed from the Agora room, register callbacks with the HiFiAudio library:

    ```typescript
    HiFiAudio.on("remote-source-connected", (uid) => { ... });
    HiFiAudio.on("remote-source-disconnected", (uid) => { ... });
    ```

    There are additional callbacks that can be used for more advanced features.
 
5. Call join

   Instantiate a specific TransportManager, and then call join.

    ```typescript
    document.querySelector('join').addEventListener('click', async function() {
        let transport = new TransportManagerAgora(appID, () => { return token; })
        let localUid = transport.generateUniqueID();
        await HiFiAudio.join(transport,
                             localUid,
                             channelName,
                             { x: 2, y: 3, o: 0 }, // initial character position
                             thresholdValue,
                             enableVideo,
                             enableMetaData);
    });
    ```
 
    Calling HiFiAudio.join will connect to an Agora room and wrap the connection with HRTF spatialization.  After joining the room, a character's position can be updated with

    ```typescript
    HiFiAudio.setPosition({ x: ..., y: ..., o: ...})
    ```

    More information about the agoraAppID, agoraToken, and agoraChannelName parameters can be found in Agora's quick-start documentation.
 
6. When finished, call leave

    Once the user's session is complete, disconnect from the Agora channel by calling

    ```typescript
    await HiFiAudio.leave();
    ```
